{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from craftax.craftax_env import make_craftax_env_from_name\n",
    "from nicewebrl.nicejax import TimestepWrapper\n",
    "import jax\n",
    "import flax.linen as nn\n",
    "from typing import Optional, Any\n",
    "import functools\n",
    "import flax.struct as struct\n",
    "import jax.numpy as jnp\n",
    "from flax.core import unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Craftax textures from cache.\n",
      "Textures successfully loaded from cache.\n"
     ]
    }
   ],
   "source": [
    "env = make_craftax_env_from_name(\"Craftax-Symbolic-v1\", auto_reset=False)\n",
    "env = TimestepWrapper(env)\n",
    "env_params = env.default_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miste/nicewebrl/venv/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n"
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, _rng = jax.random.split(rng)\n",
    "rngs = jax.random.split(_rng, 3)\n",
    "\n",
    "# Get an initial state and observation\n",
    "init_timestep = env.reset(rngs[0], env_params)\n",
    "\n",
    "# Pick random action\n",
    "action = env.action_space(env_params).sample(rngs[1])\n",
    "\n",
    "# Step environment\n",
    "timestep = env.step(rngs[2], init_timestep, action, env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        # --- Environment Settings ---\n",
    "        \"ENV_NAME\": \"Craftax-Symbolic-v1\", # Example, adjust as needed\n",
    "        \"NUM_ENVS\": 32,  # Number of parallel environments (PureJaxRL DQN used 10, can increase)\n",
    "\n",
    "        # --- Training Loop Settings ---\n",
    "        \"TOTAL_TIMESTEPS\": 1_000_000,    # Total environment steps\n",
    "        \"TRAINING_INTERVAL\": 5,          # How many env steps per actor sequence collection\n",
    "        \"LEARNING_STARTS\": 10_000,       # Timesteps before learning begins\n",
    "        \"TARGET_UPDATE_INTERVAL\": 1_000, # How many LEARNER UPDATES between target network syncs (R2D2 uses ~2500 steps)\n",
    "\n",
    "        # --- Network Settings ---\n",
    "        \"RNN_HIDDEN_DIM\": 256,     # Size of RNN hidden state (Dyna code used 256)\n",
    "        \"ENCODER_HIDDEN_DIM\": 512, # Hidden dim for observation encoder MLP\n",
    "        \"NUM_ENCODER_LAYERS\": 0,   # Hidden layers for observation encoder MLP\n",
    "        \"Q_HIDDEN_DIM\": 1024,      # Hidden dim for Q-head MLP (Dyna code used 512)\n",
    "        \"NUM_Q_LAYERS\": 2,         # Hidden layers for Q-head MLP (Dyna code used 1)\n",
    "        \"USE_BIAS\": True,          # Whether to use bias in Dense layers\n",
    "\n",
    "        # --- Optimizer Settings ---\n",
    "        \"LR\": 3e-4,\n",
    "        \"LR_LINEAR_DECAY\": False,  # Whether to use linear LR decay\n",
    "        \"EPS_ADAM\": 1e-5,          # Adam optimizer epsilon (ACME default 1e-5)\n",
    "        \"MAX_GRAD_NORM\": 80,       # Gradient clipping norm (ACME default 40.0)\n",
    "        \"TAU\": 1.0,\n",
    "\n",
    "        # --- Buffer Settings ---\n",
    "        \"BUFFER_SIZE\": 50_000,     # Total transitions in buffer (R2D2 often uses 1M+, adjust based on memory)\n",
    "        \"TOTAL_BATCH_SIZE\": 1280,  # Total transitions sampled from buffer\n",
    "        \"SAMPLE_BATCH_SIZE\": 32,   # Batch size sampled from buffer for learning (e.g., 32, 64)\n",
    "        \"SAMPLING_PERIOD\": 1,      # Store sequences overlapping by N-1 steps (1 is standard)\n",
    "\n",
    "        # --- Loss Function Settings ---\n",
    "        \"GAMMA\": 0.99,             # Discount factor\n",
    "        \"TD_LAMBDA\": 0.9,          # TD-Lambda parameter\n",
    "        \"STEP_COST\": 0.0,          # Optional cost added per step (DynaLossFn default 0.0)\n",
    "        \"ONLINE_COEFF\": 1.0,       # Weight for the loss on real data\n",
    "        \"DYNA_COEFF\": 1.0,         # Weight for the loss on simulated data (DynaLossFn default 1.0)\n",
    "\n",
    "        # --- Dyna Simulation Settings ---\n",
    "        \"NUM_SIMULATIONS\": 2,       # Number of parallel simulations per starting state (DynaLossFn default 2)\n",
    "        \"SIMULATION_LENGTH\": 10,    # Length of each simulated rollout (DynaLossFn default 5)\n",
    "        \"WINDOW_SIZE\": 1,           # Number of windows to use, must be 1 for DynaLossFn\n",
    "\n",
    "        # --- Actor Settings (Exploration) ---\n",
    "        # Choose one exploration strategy\n",
    "        \"NUM_EPSILONS\": 256,        # Number of epsilon schedules\n",
    "        \"EPSILON_MIN\": 0.05,        # Minimum epsilon\n",
    "        \"EPSILON_MAX\": 0.9,         # Maximum epsilon\n",
    "        \"EPSILON_BASE\": 0.1,        # Base epsilon\n",
    "\n",
    "        # --- Logging ---\n",
    "        \"LEARNER_LOG_PERIOD\": 500,  # How many LEARNER UPDATES between logging losses/metrics\n",
    "        \"GRADIENT_LOG_PERIOD\": 500, # How many GRADIENT UPDATES between logging losses/metrics\n",
    "        \"LEARNER_EXTRA_LOG_PERIOD\": 5_000, # How many LEARNER UPDATES between extra logging\n",
    "\n",
    "        # --- Miscellaneous ---\n",
    "        \"SEED\": 1,\n",
    "        \"NUM_SEEDS\": 1,\n",
    "        \"ENTITY\": \"hoonshin\",\n",
    "        \"PROJECT\": \"dyna-crafter\",\n",
    "        \"WANDB_MODE\": \"disabled\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Predictions:\n",
    "    q_vals: jax.Array\n",
    "    state: struct.PyTreeNode\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    hidden_dim: int\n",
    "    out_dim: Optional[int] = None\n",
    "    num_layers: int = 1\n",
    "    use_bias: bool = True\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        for _ in range(self.num_layers):\n",
    "            x = nn.Dense(self.hidden_dim, use_bias=self.use_bias)(x)\n",
    "            x = jax.nn.leaky_relu(x)\n",
    "\n",
    "        x = nn.Dense(self.out_dim or self.hidden_dim, use_bias=self.use_bias)(x)\n",
    "        return x\n",
    "\n",
    "class DynaAgent(nn.Module):\n",
    "    config: dict\n",
    "    env: TimestepWrapper\n",
    "    env_params: Any\n",
    "\n",
    "    def setup(self):\n",
    "        self.encoder = MLP(\n",
    "            hidden_dim=self.config[\"ENCODER_HIDDEN_DIM\"],\n",
    "            num_layers=self.config[\"NUM_ENCODER_LAYERS\"],\n",
    "            use_bias=self.config[\"USE_BIAS\"],\n",
    "            name=\"encoder_mlp\",\n",
    "        )\n",
    "        self.q_head = MLP(\n",
    "            hidden_dim=self.config[\"Q_HIDDEN_DIM\"],\n",
    "            out_dim=self.env.action_space(self.env_params).n,\n",
    "            num_layers=self.config[\"NUM_Q_LAYERS\"],\n",
    "            use_bias=self.config[\"USE_BIAS\"],\n",
    "            name=\"q_head_mlp\",\n",
    "        )\n",
    "        self.rnn = nn.GRUCell(\n",
    "            features=self.config[\"RNN_HIDDEN_DIM\"],\n",
    "            name=\"gru_cell\"\n",
    "        )\n",
    "\n",
    "        # Cache config values for use during scan (avoid dict access in traced code)\n",
    "        self.hidden_size = self.config[\"RNN_HIDDEN_DIM\"]\n",
    "        self.num_envs = self.config[\"NUM_ENVS\"]\n",
    "\n",
    "    @functools.partial(\n",
    "        nn.scan,\n",
    "        variable_broadcast=\"params\",\n",
    "        in_axes=0,\n",
    "        out_axes=0,\n",
    "        split_rngs={\"params\": False},\n",
    "    )\n",
    "    def __call__(self, carry, x):\n",
    "        \"\"\"\n",
    "        carry: GRU hidden state [batch, hidden_size]\n",
    "        x: tuple of (obs, reset flags)\n",
    "           obs: [T, B, obs_dim...], resets: [T, B]\n",
    "        \"\"\"\n",
    "        rnn_state = carry\n",
    "        obs, resets = x  # each [batch, ...]\n",
    "\n",
    "        # Reinitialize RNN state for environments that have reset\n",
    "        rnn_state = jnp.where(\n",
    "            resets[:, None],  # [batch, 1]\n",
    "            self.initialize_carry(resets.shape[0], self.hidden_size),  # [batch, hidden]\n",
    "            rnn_state\n",
    "        )\n",
    "\n",
    "        embeds = self.encoder(obs)  # [batch, embedding_dim]\n",
    "        next_rnn_state, rnn_out = self.rnn(rnn_state, embeds)  # both [batch, hidden]\n",
    "        q_vals = self.q_head(rnn_out)  # [batch, num_actions]\n",
    "\n",
    "        preds = Predictions(q_vals=q_vals, state=next_rnn_state)\n",
    "        return next_rnn_state, preds\n",
    "    \n",
    "    @staticmethod\n",
    "    def initialize_carry(batch_size, hidden_size):\n",
    "        return jnp.zeros((batch_size, hidden_size))\n",
    "\n",
    "    def apply_world_model(self, timestep: struct.PyTreeNode, action: jax.Array, rng: jax.Array) -> struct.PyTreeNode:\n",
    "        \"\"\"\n",
    "        Simulates one step using the 'world model' (ground truth env).\n",
    "        This wraps the true `env.step` function.\n",
    "        \"\"\"\n",
    "        def step_fn(rng, ts, act):\n",
    "            return self.env.step(rng, ts, act, self.env_params)\n",
    "\n",
    "        rngs = jax.random.split(rng, self.num_envs)\n",
    "        next_timestep = jax.vmap(step_fn)(rngs, timestep, action)\n",
    "        return next_timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DynaAgent(\n",
    "            config=config,\n",
    "            env=env,\n",
    "            env_params=env_params,\n",
    "        )\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "init_x = (\n",
    "    jnp.zeros(\n",
    "        (1, config[\"NUM_ENVS\"], *env.observation_space(env_params).shape)\n",
    "    ),\n",
    "    jnp.zeros((1, config[\"NUM_ENVS\"])),\n",
    ")\n",
    "init_carry = DynaAgent.initialize_carry(config[\"NUM_ENVS\"], config[\"RNN_HIDDEN_DIM\"])\n",
    "online_params = agent.init(init_rng, init_carry, init_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'encoder_mlp': {'Dense_0': {'bias': (512,),\n",
       "    'kernel': (8268, 512)}},\n",
       "  'gru_cell': {'hn': {'bias': (256,), 'kernel': (256, 256)},\n",
       "   'hr': {'kernel': (256, 256)},\n",
       "   'hz': {'kernel': (256, 256)},\n",
       "   'in': {'bias': (256,), 'kernel': (512, 256)},\n",
       "   'ir': {'bias': (256,), 'kernel': (512, 256)},\n",
       "   'iz': {'bias': (256,), 'kernel': (512, 256)}},\n",
       "  'q_head_mlp': {'Dense_0': {'bias': (1024,), 'kernel': (256, 1024)},\n",
       "   'Dense_1': {'bias': (1024,), 'kernel': (1024, 1024)},\n",
       "   'Dense_2': {'bias': (43,), 'kernel': (1024, 43)}}}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_util.tree_map(lambda x: x.shape, unfreeze(online_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 256)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_rnn = nn.GRUCell(features=config[\"RNN_HIDDEN_DIM\"])\n",
    "init_carry = dummy_rnn.initialize_carry(jax.random.PRNGKey(0), input_shape=(config[\"NUM_ENVS\"], config[\"RNN_HIDDEN_DIM\"]))\n",
    "init_carry.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8268"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space(env_params).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8268,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space(env_params).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0., dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = jnp.zeros((1,))\n",
    "x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = jnp.zeros((11, 2))\n",
    "x[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
